{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LwSS0ZESZmP"
   },
   "source": [
    "Plant Disease Detection \n",
    "Access: open, available at New Plant Disease Dataset \n",
    "\n",
    "Data Description \n",
    "\n",
    "The data records contain 54,309 images. The images span 14 crop species: Apple, Blueberry, Cherry, Corn, Grape, Orange, Peach, Bell Pepper, Potato, Raspberry, Soybean, Squash, Strawberry, Tomato. In containes images of 17 fungal diseases, 4 bacterial diseases, 2 mold (oomycete) diseases, 2 viral disease, and 1 disease caused by a mite. 12 crop species also have images of healthy leaves that are not visibly affected by a disease  \n",
    "\n",
    "Predictive task  \n",
    "\n",
    "The predictive task can change depending on the images selected: one can predict plant disease vs plant good health or plant type.  \n",
    "\n",
    "Related works:  \n",
    "\n",
    "[1] Schuler, Joao Paulo Schwarz, et al. \"Color-aware two-branch dcnn for efficient plant disease classification.\" MENDEL. Vol. 28. No. 1. 2022.  \n",
    "\n",
    "[2] Mohanty, Sharada P., David P. Hughes, and Marcel Salathé. \"Using deep learning for image-based plant disease detection.\" Frontiers in plant science 7 (2016): 1419."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4468,
     "status": "ok",
     "timestamp": 1685855157343,
     "user": {
      "displayName": "Guglielmo Tedeschi",
      "userId": "12427337079834260043"
     },
     "user_tz": -120
    },
    "id": "NDI0FYapTXzE",
    "outputId": "13081cfe-4b72-401c-afca-56d3d47efc9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
      "Skipping, found downloaded files in \"./new-plant-diseases-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets\n",
    "\n",
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset/download?datasetVersionNumber=2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADrNPEt6L0mz"
   },
   "source": [
    "\n",
    "{\"username\":\"`guglielmotedeschi`\",\n",
    "\n",
    "\n",
    "\"key\":\"`5306be7ca91268007d1f0059dbdb0b68`\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rw0nrKBxJJ2"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7490,
     "status": "ok",
     "timestamp": 1685855171170,
     "user": {
      "displayName": "Guglielmo Tedeschi",
      "userId": "12427337079834260043"
     },
     "user_tz": -120
    },
    "id": "60Ty1syTpCG1",
    "outputId": "6e397c49-d492-447a-8aa3-174cbc54a4aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu118\n",
      "torchvision version: 0.15.2+cu118\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5av7rP9Zyofi"
   },
   "outputs": [],
   "source": [
    "train_dir = \"/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
    "valid_dir = \"/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n",
    "test_dir = \"/content/new-plant-diseases-dataset/test\"\n",
    "diseases = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1685854935599,
     "user": {
      "displayName": "Guglielmo Tedeschi",
      "userId": "12427337079834260043"
     },
     "user_tz": -120
    },
    "id": "1pkZzAZlpcD0",
    "outputId": "4750aece-c183-41f8-a558-89b09723ff56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total disease classes are: 38\n",
      "['Strawberry___Leaf_scorch', 'Potato___Late_blight', 'Pepper,_bell___healthy', 'Grape___Esca_(Black_Measles)', 'Peach___Bacterial_spot', 'Blueberry___healthy', 'Strawberry___healthy', 'Pepper,_bell___Bacterial_spot', 'Tomato___Bacterial_spot', 'Corn_(maize)___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Soybean___healthy', 'Grape___healthy', 'Potato___Early_blight', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Leaf_Mold', 'Tomato___Early_blight', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Apple___Apple_scab', 'Tomato___Septoria_leaf_spot', 'Tomato___healthy', 'Raspberry___healthy', 'Tomato___Late_blight', 'Apple___healthy', 'Tomato___Tomato_mosaic_virus', 'Tomato___Target_Spot', 'Squash___Powdery_mildew', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Apple___Black_rot', 'Potato___healthy', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Apple___Cedar_apple_rust', 'Peach___healthy', 'Corn_(maize)___Common_rust_', 'Orange___Haunglongbing_(Citrus_greening)', 'Grape___Black_rot']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total disease classes are: {}\".format(len(diseases)))\n",
    "print(diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xik53PKBHDZ"
   },
   "source": [
    "#A look on Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjA8683t0F1U"
   },
   "outputs": [],
   "source": [
    "plants = []\n",
    "NumberOfDiseases = 0\n",
    "for plant in diseases:\n",
    "    if plant.split('___')[0] not in plants:\n",
    "        plants.append(plant.split('___')[0])\n",
    "    if plant.split('___')[1] != 'healthy':\n",
    "        NumberOfDiseases += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1685601951943,
     "user": {
      "displayName": "Guglielmo Tedeschi",
      "userId": "12427337079834260043"
     },
     "user_tz": -120
    },
    "id": "oueUYfSV0JSO",
    "outputId": "22d2bb81-d8dc-486b-b921-1c1f673ac0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Plants are: \n",
      "['Tomato', 'Grape', 'Corn_(maize)', 'Apple', 'Cherry_(including_sour)', 'Orange', 'Raspberry', 'Potato', 'Blueberry', 'Strawberry', 'Peach', 'Squash', 'Pepper,_bell', 'Soybean']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique Plants are: \\n{plants}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fen6tCX0MuN"
   },
   "outputs": [],
   "source": [
    "print(\"Number of plants: {}\".format(len(plants)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTWrbOqR0OdB"
   },
   "outputs": [],
   "source": [
    "print(\"Number of diseases: {}\".format(NumberOfDiseases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUluzHRm0i-z"
   },
   "outputs": [],
   "source": [
    "nums = {}\n",
    "for disease in diseases:\n",
    "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
    "    \n",
    "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
    "\n",
    "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
    "img_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6k2y8Vek0rV9"
   },
   "outputs": [],
   "source": [
    "# plotting number of images available for each disease\n",
    "index = [n for n in range(38)]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
    "plt.xlabel('Plants/Diseases', fontsize=10)\n",
    "plt.ylabel('No of images available', fontsize=10)\n",
    "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
    "plt.title('Images per each class of plant disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1685601953382,
     "user": {
      "displayName": "Guglielmo Tedeschi",
      "userId": "12427337079834260043"
     },
     "user_tz": -120
    },
    "id": "745rC2LQ0zSF",
    "outputId": "5fd552b7-db5d-476d-886f-a0449921d9e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70295 images for training\n"
     ]
    }
   ],
   "source": [
    "n_train = 0\n",
    "for value in nums.values():\n",
    "    n_train += value\n",
    "print(f\"There are {n_train} images for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGw25CK74Hqg"
   },
   "source": [
    "#to Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzthgDmC4JwI"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
    "\n",
    "train = ImageFolder(train_dir, transform=ToTensor()) # ToTensor images come as PIL format, we want to turn into Torch tensors\n",
    "valid = ImageFolder(valid_dir, transform=ToTensor()) \n",
    "test = ImageFolder(test_dir, transform=ToTensor())\n",
    "\n",
    "class_names= train.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkGgcT3R4ats"
   },
   "outputs": [],
   "source": [
    "img, label = train[0]\n",
    "print(img.shape, label)\n",
    "print(\"n classes:\",len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mx-_UBHVeGYr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train), size=[1]).item()\n",
    "    img, label = train[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uySBx-s3e2RV"
   },
   "source": [
    "Prepare a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1685855172105,
     "user": {
      "displayName": "Guglielmo Tedeschi",
      "userId": "12427337079834260043"
     },
     "user_tz": -120
    },
    "id": "cGjazWwn5k29",
    "outputId": "7cedbf7b-fdf1-41ef-c9a5-a92411d2fb07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa96893c890>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h60_XFOWBZih"
   },
   "source": [
    "#Convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1685855172105,
     "user": {
      "displayName": "Guglielmo Tedeschi",
      "userId": "12427337079834260043"
     },
     "user_tz": -120
    },
    "id": "gY1uYJXw56OJ",
    "outputId": "b113672c-7d93-4fb2-ee3a-f3689f444f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7fa963f86aa0>, <torch.utils.data.dataloader.DataLoader object at 0x7fa963f86b00>)\n",
      "Length of train dataloader: 138 batches of 512\n",
      "Length of test dataloader: 1 batches of 512\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader # DataLoader permette di splittare il dataset in batches \n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dl, test_dl}\") \n",
    "print(f\"Length of train dataloader: {len(train_dl)} batches of {batch_size}\")\n",
    "print(f\"Length of test dataloader: {len(test_dl)} batches of {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-n3k-JNqIj1"
   },
   "outputs": [],
   "source": [
    "# for moving data into GPU (if available)\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# for moving data to device (CPU or GPU)\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# for loading in the device (GPU if available else CPU)\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCy3vFozqe93"
   },
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMYONfuO6qg4"
   },
   "source": [
    "Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1685855175344,
     "user": {
      "displayName": "Guglielmo Tedeschi",
      "userId": "12427337079834260043"
     },
     "user_tz": -120
    },
    "id": "hxtiHxk3AmsS",
    "outputId": "437ac2a9-604c-4fbe-8e3b-01d37b125d60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plant(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Plant(nn.Module):\n",
    "    def __init__(self, input_shape: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential (\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4)\n",
    "        )\n",
    "        self.block_2 = nn.Sequential (\n",
    "            nn.Conv2d(in_channels=128,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Conv2d(in_channels=256,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512, \n",
    "                      #bisogna moltiplicare basandosi sull output.shape del self block_2\n",
    "                      #motivo per cui ho printato x.shape nel forward                                    \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "       #print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        #print(x.shape)\n",
    "        return x \n",
    "  \n",
    "torch.manual_seed(42)\n",
    "convo_nepsi = Plant(input_shape=3,\n",
    "                      output_shape=len(class_names))\n",
    "  \n",
    "# Setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=convo_nepsi.parameters(), \n",
    "                             lr=0.01)\n",
    "\n",
    "convo_nepsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bx-fOGwkZdv"
   },
   "source": [
    "Function for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zwn2TYNGuKDc"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=convo_nepsi.parameters(), \n",
    "                             lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DxgfaJhwyeQ"
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer, accuracy_fn):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        print(\"zero grad\")\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "        print(\"loss back\")\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "        print(\"optimizing\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader, model: torch.nn.Module, loss_fn: torch.nn.Module, accuracy_fn):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oym8e0dpw2C9"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time: {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJFbgCJ0w7AN"
   },
   "outputs": [],
   "source": [
    "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gs8cE46Zw_DA",
    "outputId": "282f5bef-54f8-4c9d-c574-18d386512130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dl, \n",
    "        model=convo_nepsi, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "    test_step(data_loader=test_dl,\n",
    "        model=convo_nepsi,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "\n",
    "train_time_end= timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start, end=train_time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eE7-VNk3xMFi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTZXYu25ccIWMnKiyo8qIh",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
